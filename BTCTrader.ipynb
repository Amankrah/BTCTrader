{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install ccxt\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/libta-lib0_0.4.0-oneiric1_amd64.deb -qO libta.deb\n",
        "!wget https://launchpad.net/~mario-mariomedina/+archive/ubuntu/talib/+files/ta-lib0-dev_0.4.0-oneiric1_amd64.deb -qO ta.deb\n",
        "!dpkg -i libta.deb ta.deb\n",
        "!pip install TA-Lib\n"
      ],
      "metadata": {
        "id": "ksxSOQ3UuJHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "XQPa6VRWe5d6"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import ccxt\n",
        "import talib"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import numpy as np\n",
        "from talib import RSI, BBANDS, MACD\n",
        "\n",
        "# Load the historical BTC/USD data\n",
        "btc_usd_data = pd.read_csv('/content/BTC-USD.csv')  # Change this to the path where you stored BTC-USD.csv\n",
        "\n",
        "# Convert the 'Date' column to datetime format\n",
        "btc_usd_data['Date'] = pd.to_datetime(btc_usd_data['Date'])\n",
        "\n",
        "# Drop the 'Adj Close' column\n",
        "btc_usd_data.drop('Adj Close', axis=1, inplace=True)\n",
        "\n",
        "# Calculate 24hr Close Change\n",
        "btc_usd_data['24hr_Close_Change'] = btc_usd_data['Close'].diff() / btc_usd_data['Close'].shift(1) * 100\n",
        "\n",
        "# Market Direction based on Close price\n",
        "btc_usd_data['Market_Direction'] = 0\n",
        "btc_usd_data.loc[btc_usd_data['Close'] > btc_usd_data['Close'].shift(1), 'Market_Direction'] = 1\n",
        "btc_usd_data.loc[btc_usd_data['Close'] < btc_usd_data['Close'].shift(1), 'Market_Direction'] = -1\n",
        "\n",
        "# Calculate Volume Change\n",
        "btc_usd_data['Volume_Change'] = btc_usd_data['Volume'].diff() / btc_usd_data['Volume'].shift(1) * 100\n",
        "\n",
        "# Calculate RSI\n",
        "btc_usd_data['RSI'] = RSI(btc_usd_data['Close'], timeperiod=14)\n",
        "\n",
        "# Calculate Bollinger Bands\n",
        "upper, middle, lower = BBANDS(btc_usd_data['Close'], timeperiod=20)\n",
        "btc_usd_data['upper_band'] = upper\n",
        "btc_usd_data['middle_band'] = middle\n",
        "btc_usd_data['lower_band'] = lower\n",
        "\n",
        "# Calculate MACD\n",
        "macd, signal, _ = MACD(btc_usd_data['Close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "btc_usd_data['MACD'] = macd\n",
        "btc_usd_data['Signal_Line'] = signal\n",
        "\n",
        "# Handle NaN values\n",
        "btc_usd_data.fillna(0, inplace=True)\n",
        "\n",
        "# Normalize columns\n",
        "scaler = MinMaxScaler()\n",
        "btc_usd_data[['Open', 'High', 'Low', 'Close', 'Volume']] = scaler.fit_transform(btc_usd_data[['Open', 'High', 'Low', 'Close', 'Volume']])\n",
        "\n",
        "# Save the modified DataFrame\n",
        "btc_usd_data.to_csv('/content/BTC-USD_new_with_indicators.csv', index=False)  # Change this to the path where you want to save the new CSV file\n"
      ],
      "metadata": {
        "id": "VW3PGoCd1qRB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "data = pd.read_csv('/content/BTC-USD_new_with_indicators.csv')\n",
        "data = data.dropna()\n",
        "\n",
        "features = ['Close', 'RSI', 'upper_band', 'middle_band', 'lower_band', 'MACD', 'Signal_Line']  # Change this line accordingly\n",
        "X = data[features]\n",
        "y = data['Market_Direction']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "8Pe7_Hk0fKRN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DQN model\n",
        "class DQN(tf.keras.Model):\n",
        "    def __init__(self, state_shape, action_shape):\n",
        "        super(DQN, self).__init__()\n",
        "        self.layer1 = tf.keras.layers.Dense(64, activation='relu', input_shape=state_shape)\n",
        "        self.layer2 = tf.keras.layers.Dense(32, activation='relu')\n",
        "        self.layer3 = tf.keras.layers.Dense(action_shape)\n",
        "\n",
        "    def call(self, state):\n",
        "        x = self.layer1(state)\n",
        "        x = self.layer2(x)\n",
        "        return self.layer3(x)"
      ],
      "metadata": {
        "id": "K8UbQhswfdvf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the DQN model and target model\n",
        "state_shape = (X_train.shape[1], )  # Shape of one state\n",
        "action_shape = 3  # Number of actions: Buy, Hold, Sell\n",
        "dqn_model = DQN(state_shape, action_shape)\n",
        "\n",
        "# Compile the model\n",
        "dqn_model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "lPlGuLULfuiS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model if resuming training\n",
        "checkpoint_path = \"dqn_model_checkpoint\"\n",
        "if tf.train.latest_checkpoint(checkpoint_path):\n",
        "    dqn_model.load_weights(checkpoint_path)"
      ],
      "metadata": {
        "id": "v0jMJ8hJiehW"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TradingEnvironment:\n",
        "    def __init__(self, data, initial_balance=10000):\n",
        "        self.data = data\n",
        "        self.initial_balance = initial_balance\n",
        "        self.balance = initial_balance\n",
        "        self.current_step = 0\n",
        "        self.current_price = self.data[self.current_step, 0]  # Assuming the price is in the first column\n",
        "        self.position = None\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        self.current_price = self.data[self.current_step, 0]  # Assuming the price is in the first column\n",
        "\n",
        "        reward = 0\n",
        "        done = self.current_step == len(self.data) - 1\n",
        "\n",
        "        # 0: Buy, 1: Hold, 2: Sell\n",
        "        if action == 0 and self.position is None:  # Buy\n",
        "            self.position = self.current_price\n",
        "        elif action == 2 and self.position is not None:  # Sell\n",
        "            reward = self.current_price - self.position\n",
        "            self.balance += reward\n",
        "            self.position = None\n",
        "\n",
        "        next_state = self.data[self.current_step]\n",
        "        return next_state, float(reward), done  # Making sure reward is a float\n",
        "\n",
        "    def reset(self):\n",
        "        self.balance = self.initial_balance\n",
        "        self.current_step = 0\n",
        "        self.current_price = self.data[self.current_step, 0]  # Assuming the price is in the first column\n",
        "        self.position = None\n",
        "        return self.data[self.current_step]\n"
      ],
      "metadata": {
        "id": "h5ihJ1uaf5Su"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize environment (modify your existing TradingEnvironment class accordingly)\n",
        "env = TradingEnvironment(data=X_train)"
      ],
      "metadata": {
        "id": "x2nKrtl9hI8p"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize replay buffer\n",
        "replay_buffer = []\n",
        "\n",
        "# Training parameters\n",
        "n_episodes = 1000\n",
        "batch_size = 32\n",
        "gamma = 0.99\n",
        "epsilon = 0.1\n",
        "\n",
        "# Training loop\n",
        "for episode in range(1, n_episodes + 1):\n",
        "    state = env.reset()\n",
        "    done = False\n",
        "\n",
        "    while not done:\n",
        "        if random.random() < epsilon:\n",
        "            action = random.choice([0, 1, 2])\n",
        "        else:\n",
        "            action = np.argmax(dqn_model.predict(state.reshape(1, -1)))\n",
        "\n",
        "        next_state, reward, done = env.step(action)\n",
        "        replay_buffer.append((state, action, reward, next_state, done))\n",
        "\n",
        "        if len(replay_buffer) > batch_size:\n",
        "            minibatch = random.sample(replay_buffer, batch_size)\n",
        "            states, actions, rewards, next_states, dones = zip(*minibatch)\n",
        "            states, actions, rewards, next_states, dones = np.array(states), np.array(actions), np.array(rewards), np.array(next_states), np.array(dones)\n",
        "\n",
        "            q_values = dqn_model.predict(states)\n",
        "            next_q_values = dqn_model.predict(next_states)\n",
        "            next_q_value = np.max(next_q_values, axis=1)\n",
        "\n",
        "            target_q_values = q_values\n",
        "            target_q_values[np.arange(batch_size), actions] = rewards + (gamma * next_q_value * (1 - dones))\n",
        "\n",
        "            dqn_model.fit(states, target_q_values, epochs=1, verbose=0)\n",
        "\n",
        "        state = next_state\n",
        "\n",
        "    # Save model checkpoint\n",
        "    dqn_model.save_weights(checkpoint_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4s4kIFjTiuiJ",
        "outputId": "a4da8f0d-3ea7-4bf9-ac57-4ebbbc82836a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 331ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 50ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 95ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 65ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "1/1 [==============================] - 0s 121ms/step\n",
            "1/1 [==============================] - 0s 73ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test model\n",
        "env = TradingEnvironment(data=X_test)\n",
        "state = env.reset()\n",
        "done = False\n",
        "total_reward = 0\n",
        "num_profitable_trades = 0\n",
        "num_loss_making_trades = 0\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(dqn_model.predict(state.reshape(1, -1)))\n",
        "    next_state, reward, done = env.step(action)\n",
        "    total_reward += reward\n",
        "    if reward > 0:\n",
        "        num_profitable_trades += 1\n",
        "    elif reward < 0:\n",
        "        num_loss_making_trades += 1\n",
        "    state = next_state\n",
        "\n",
        "print(f\"Total reward from test set: {total_reward}\")\n",
        "print(f'Number of Profitable Trades: {num_profitable_trades}')\n",
        "print(f'Number of Loss-making Trades: {num_loss_making_trades}')"
      ],
      "metadata": {
        "id": "xtzofRgLjHFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import ccxt  # Library to interact with crypto exchange APIs\n",
        "\n",
        "# Initialize Binance API\n",
        "binance = ccxt.binance({\n",
        "    'apiKey': 'YOUR_API_KEY',\n",
        "    'secret': 'YOUR_API_SECRET'\n",
        "})\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from talib import RSI, BBANDS, MACD\n"
      ],
      "metadata": {
        "id": "pM-8ZHuF3iZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a DataFrame to keep a rolling window of data\n",
        "rolling_data = pd.DataFrame()\n",
        "\n",
        "# Function to fetch real-time BTC/USD daily data (OHLCV)\n",
        "def fetch_real_time_data():\n",
        "    ohlcv = binance.fetch_ohlcv('BTC/USDT', '1d')  # 1d specifies daily data\n",
        "    latest_data = ohlcv[-1]  # Get the latest data\n",
        "    return latest_data  # You may want to select specific fields\n",
        "\n",
        "# Function to apply technical indicators (modify this based on your specific needs)\n",
        "def apply_technical_indicators(data):\n",
        "    # Apply RSI, Bollinger Bands, MACD\n",
        "    data['rsi'] = talib.RSI(data['close'], timeperiod=14)\n",
        "    data['upper_band'], data['middle_band'], data['lower_band'] = talib.BBANDS(data['close'], timeperiod=20)\n",
        "    data['macd'], data['signal'], _ = talib.MACD(data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "    return data\n",
        "\n",
        "# Implement paper trade (modify this to your real-world data)\n",
        "real_world_data = fetch_real_time_data()  # Fetch real-world data\n",
        "real_world_data = apply_technical_indicators(real_world_data)  # Apply technical indicators\n",
        "paper_env = TradingEnvironment(data=real_world_data)\n",
        "\n",
        "state = paper_env.reset()\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(dqn_model.predict(state.reshape(1, -1)))\n",
        "    next_state, reward, done = paper_env.step(action)\n",
        "    state = next_state\n",
        "\n",
        "print(\"Finished paper trading.\")\n"
      ],
      "metadata": {
        "id": "BqQfaIZn3rAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize a DataFrame to keep a rolling window of data\n",
        "rolling_data = pd.DataFrame()\n",
        "\n",
        "def fetch_real_time_data(window_size=50):\n",
        "    global rolling_data\n",
        "\n",
        "    # Fetch latest OHLCV data\n",
        "    ohlcv = binance.fetch_ohlcv('BTC/USDT', '1d')\n",
        "    latest_data = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume']).tail(1)\n",
        "\n",
        "    # Add to rolling data\n",
        "    rolling_data = pd.concat([rolling_data, latest_data]).tail(window_size)\n",
        "\n",
        "    # Calculate RSI\n",
        "    rolling_data['rsi'] = RSI(rolling_data['close'], timeperiod=14)\n",
        "\n",
        "    # Calculate Bollinger Bands\n",
        "    upper, middle, lower = BBANDS(rolling_data['close'], timeperiod=20)\n",
        "    rolling_data['upper_band'] = upper\n",
        "    rolling_data['middle_band'] = middle\n",
        "    rolling_data['lower_band'] = lower\n",
        "\n",
        "    # Calculate MACD\n",
        "    macd, signal, _ = MACD(rolling_data['close'], fastperiod=12, slowperiod=26, signalperiod=9)\n",
        "    rolling_data['macd'] = macd\n",
        "    rolling_data['signal'] = signal\n",
        "\n",
        "    # Assuming your model uses these features: ['close', 'rsi', 'upper_band', 'middle_band', 'lower_band', 'macd', 'signal']\n",
        "    latest_data_with_indicators = rolling_data[['close', 'rsi', 'upper_band', 'middle_band', 'lower_band', 'macd', 'signal']].tail(1).values\n",
        "\n",
        "    return latest_data_with_indicators\n",
        "\n",
        "\n",
        "class RealTimeTradingEnvironment(TradingEnvironment):\n",
        "    def __init__(self, initial_balance=10000):\n",
        "        self.initial_balance = initial_balance\n",
        "        self.balance = initial_balance\n",
        "        self.current_step = 0\n",
        "        self.current_price = fetch_real_time_data()\n",
        "        self.position = None\n",
        "\n",
        "    def step(self, action):\n",
        "        self.current_step += 1\n",
        "        self.current_price = fetch_real_time_data()  # Fetching real-time data\n",
        "\n",
        "        reward = 0\n",
        "        done = False  # The paper trading loop will continue until you stop it\n",
        "\n",
        "        # 0: Buy, 1: Hold, 2: Sell\n",
        "        if action == 0 and self.position is None:  # Buy\n",
        "            self.position = self.current_price\n",
        "        elif action == 2 and self.position is not None:  # Sell\n",
        "            reward = self.current_price - self.position\n",
        "            self.balance += reward\n",
        "            self.position = None\n",
        "\n",
        "        next_state = self.current_price\n",
        "        return next_state, float(reward), done\n",
        "\n",
        "    # Rest of the functions remain the same\n",
        "\n",
        "# Initialize the real-time environment\n",
        "paper_env = RealTimeTradingEnvironment()\n",
        "state = paper_env.reset()\n",
        "done = False\n",
        "\n",
        "# Paper trading loop\n",
        "while not done:\n",
        "    action = np.argmax(dqn_model.predict(state.reshape(1, -1)))\n",
        "    next_state, reward, done = paper_env.step(action)\n",
        "    state = next_state\n",
        "    print(f\"Action taken: {action}, Reward received: {reward}, Balance: {paper_env.balance}\")\n",
        "\n",
        "print(\"Finished paper trading.\")\n"
      ],
      "metadata": {
        "id": "LwW5rRHmlM3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}